{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition task\n",
    "In this notebook I will guide you through one of the most common challenges of these days, that is, a speech recognition task. This is a **multiclassification** task, our dataset is composed of 105835.wav recordings with 35 possible labels and for each recording we have Mel-frequencies. First, we will see how to load data and how to process them. Then, we will use differnt algorithms to predict our classes. Particularly, we will deal with:\n",
    "\n",
    "1. **Decision forest**\n",
    "2. **CNN 2D**\n",
    "3. **CNN 1D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "\n",
    "The first thing to do is to import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to load the data and then to precess them. Before starting, let's see in more details our data, which you can find here: https://surfdrive.surf.nl/files/index.php/s/A91xgk7B5kXNvfJ\n",
    "\n",
    "- **feat.npy** is an array with Mel-frequency coefficients extracted from each wav file. The features at index *i* in this array were extracted from the wav file at index *i* of the array in the file path.npy.\n",
    "- **path.npy** is an array with the order of wav files in the feat.npy array.\n",
    "- **train.csv** contains two columns: path with the filename of the recording and word with word which was pronounced in the recording. This is the training portion of the data.\n",
    "- **test.csv** is the testing portion of the data, and it has the same format as the file train.csv except that the column word is absent.\n",
    "\n",
    "For transparency reason I also described the test portion of the data. However, I do not have access to its label so for now on I will not use it. We will divide our data in training and validation sets, which is not a problem because we have enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # --------------------- LOAD DATA ------------------------ #\n",
    "\n",
    "features = np.load(\"feat.npy\", allow_pickle = True)\n",
    "path = np.load(\"path.npy\", allow_pickle = True)\n",
    "train = pd.read_csv(\"train.csv\", delimiter = \",\")\n",
    "#test = pd.read_csv(\"test.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu put it simply, in path.npy we have the \"wav name\" of the recordings and in feat.npy we have its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file with name  8d37d10e7f97ddea2eca9d39a4cf821b4457b041.wav has this set of features:\n",
      "----------------------------------------------------------\n",
      "[[-1.0160675e+01 -1.3804866e+01  9.1880971e-01 ...  1.5415058e+00\n",
      "   1.1875046e-02 -5.8664594e+00]\n",
      " [-9.9697800e+00 -1.3823588e+01 -7.0778362e-02 ...  1.5948311e+00\n",
      "   4.3481258e-01 -5.1646194e+00]\n",
      " [-9.9518738e+00 -1.2771760e+01 -1.2623003e-01 ...  3.4290311e+00\n",
      "   2.7361808e+00 -6.0621500e+00]\n",
      " ...\n",
      " [-9.9772453e+00 -1.8227636e+01  5.4514462e-01 ... -2.4311361e+01\n",
      "  -1.2033378e+01 -3.0492477e+00]\n",
      " [-9.8815651e+00 -1.3674727e+01  5.1737971e+00 ... -1.0951551e+01\n",
      "  -2.6184993e+00  1.5815194e+00]\n",
      " [-1.0164914e+01 -1.2636200e+01  4.4198503e+00 ... -5.7269883e+00\n",
      "   4.0758374e-01 -4.4462643e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The file with name \",path[0], \"has this set of features:\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the index in path and features must be the same, otherwise we risk misaligning \"wav file name - features\" and consequently, have a very bad accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now stay with me, because this is the most boring part of the project. Unfortunatly the structure of the data is not suitable to apply ML or DL algorithms, but this is fine, because we are Data Scientists and we know that we have to get \"our hands dirty\" before having fun ;).\n",
    "\n",
    "The \"problem\" is that we were given the indices of train set and test set (see train.csv and test.csv). I know, now you are thinking: \"Why in the world is this a problem? We need those!\". That is true, but the problem is that the indices of train set and test set only list their \"file name\" but not their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                           path word\n",
      "0  8d37d10e7f97ddea2eca9d39a4cf821b4457b041.wav  one\n",
      "1  9a8f761be3fa0d0a963f5612ba73e68cc0ad11ba.wav  one\n",
      "2  314cdc39f628bc68d216498b2080bcc7a549a45f.wav  one\n",
      "3  cc499e63eee4a3bcca48b5b452df04990df83570.wav  one\n",
      "4  38cdcc4d9432ce4a2fe63e0998dbca91e64b954a.wav  one\n"
     ]
    }
   ],
   "source": [
    "#print(test.head())\n",
    "print()\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we need to find a way to split our data, which are divided in path.npy and feat.npy, according to the indices in train.csv and test.csv.\n",
    "\n",
    "To do that, we first link our path.npy and feat.npy with a dictionary, key = path and value = feat. You will understand why in a moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary: key = path and value = feat\n",
    "dic = {} \n",
    "for i in range(len(path)):\n",
    "    dic[path[i]] = features[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a dictionary, we need a fuction to split all our data (now in the dictionary) into train and test sets according to the csv files. Basically, we go through all the data_frames, which are train.csv and test.csv and thanks to the information from the dictionary we can create a list for each data_frame, where in the *ith* position for both, data_frame and dictionary, we have its *i* set of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function take as argument a pandas data frame and a dictionary\n",
    "# and create a new list according to the ith position in the dataframe\n",
    "\n",
    "def create_list(data_frame,dic):\n",
    "    new_list= []\n",
    "    for i in range(len(data_frame)):\n",
    "        if data_frame[\"path\"][i] in dic.keys():\n",
    "            new_list.append(dic[data_frame[\"path\"][i]]) # in the position i we add its features thanks to the dic\n",
    "    return new_list\n",
    "\n",
    "#in order to convert a list in a numpy array we need to padd our data\n",
    "def padding(data):\n",
    "    zeros_list=[0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for example in range(len(data)):\n",
    "        if data[example].shape[0]!=99:\n",
    "            to_change=data[example].tolist()\n",
    "            for adding in range(99-len(to_change)):\n",
    "                to_change.append(zeros_list)\n",
    "            data[example]=np.array(to_change)     \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply all the defined functions and we can also get an overview of the shape so that we can sense the kinds of data we are going to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94824, 99, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split test and train \n",
    "training_data = create_list(train,dic)\n",
    "#test_data = create_list(test,dic)\n",
    "\n",
    "# padding\n",
    "training_data = padding(training_data)\n",
    "#test_data = padding(test_data)\n",
    "\n",
    "# convert to array\n",
    "training_data = np.array(training_data)\n",
    "#test_data = np.array(test_data)\n",
    "\n",
    "#check shape\n",
    "training_data.shape #,test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! We have now a tidy training data composed of 94824 examples with 99 lists of 13 elements each. We can now link the features in training_data to the file name in train.csv and the features in test_data to the file name in test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file name\n",
      " path    8d37d10e7f97ddea2eca9d39a4cf821b4457b041.wav\n",
      "word                                             one\n",
      "Name: 0, dtype: object \n",
      "\n",
      " has these features \n",
      "\n",
      "[[-1.01606750e+01 -1.38048658e+01  9.18809712e-01 ...  1.54150581e+00\n",
      "   1.18750464e-02 -5.86645937e+00]\n",
      " [-9.96977997e+00 -1.38235884e+01 -7.07783625e-02 ...  1.59483111e+00\n",
      "   4.34812576e-01 -5.16461945e+00]\n",
      " [-9.95187378e+00 -1.27717600e+01 -1.26230031e-01 ...  3.42903113e+00\n",
      "   2.73618078e+00 -6.06215000e+00]\n",
      " ...\n",
      " [-9.97724533e+00 -1.82276363e+01  5.45144618e-01 ... -2.43113613e+01\n",
      "  -1.20333776e+01 -3.04924774e+00]\n",
      " [-9.88156509e+00 -1.36747274e+01  5.17379713e+00 ... -1.09515514e+01\n",
      "  -2.61849928e+00  1.58151937e+00]\n",
      " [-1.01649141e+01 -1.26362000e+01  4.41985035e+00 ... -5.72698832e+00\n",
      "   4.07583743e-01 -4.44626427e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"This file name\\n\", train.loc[0], \"\\n\\n has these features \\n\" )# with .loc I can see all the columns of\n",
    "                                                                    # the index that I passed. See pandas documentation\n",
    "                                                                    # for more details.\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost at the end of this chapter, but first we need to encode our target. We will use the function [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), because our target is a string and it is much easier to work with integer and so we encode our labels into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target\n",
    "train_numpy = train.values # from pandas to numpy\n",
    "labels = train_numpy[:,1] # get the labels\n",
    "encoder = LabelEncoder() # generate the encoder\n",
    "encoder.fit(labels) # fit the encoder\n",
    "labels = encoder.transform(labels) # transform the labels into integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid doing this data processing again in the future, let's save these new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAVE PROCESSED DATA\n",
    "save('training_data.npy', training_data)\n",
    "save(\"labels.npy\",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create now a validation data for testing the decision forest thanks to the function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLITTING\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75859, 99, 13)\n",
      "(75859,)\n",
      "(18965, 99, 13)\n",
      "(18965,)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the accuracy of our decision forest, it is wise to do some feature engineering first. We define two functions. The first creates the mean of our signal, while the second does something a little bit more complicated, that is, it applys different statistics indices to our signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_mean(signal):\n",
    "    return np.mean(signal,axis=2)\n",
    "\n",
    "def features(signal, functions):\n",
    "    summaries=[]\n",
    "    for fn in functions:\n",
    "        summaries.append(fn(signal,axis=2))\n",
    "    return np.concatenate(summaries,axis=1)\n",
    "\n",
    "summaries = [np.mean, np.min, np.max, np.std]\n",
    "\n",
    "X_train_summaries = features(X_train, summaries)\n",
    "X_test_summaries = features(X_test, summaries)\n",
    "\n",
    "X_train_mean = features_mean(X_train)\n",
    "X_test_mean = features_mean(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to have some fun? Here I create a function in order to run the decision forest with different numbers of nodes. As you know, the number of nodes in a forest is extremely important as it allows to control for overfitting. Let's take a look at all the arguments:\n",
    "\n",
    "- **n_estimators** : this is a list and as I mentioned before, with this we can control the number of nodes\n",
    "- **X_train and X_test** : as we used 2 different kinds of feature engineering, here we can choose which one to use\n",
    "- **y_train and y_test** : regardless of wich kind of training data we use, the test set remains the same and therefore these arguments have already default values\n",
    "- **random_state** : a simple way to control randomness when looking for the best split at each node. This is useful to reproduce the accuracy.\n",
    "\n",
    "I leave you [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) the official documentation about decision forest.\n",
    "\n",
    "In conclusion, not only does this function allow us to choose the training data and the number of nodes, but it also saves the accuracy for each number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function take as argument a training and a validation data set and return the accuracy based on \n",
    "# the number of nodes, which is encode here as n_estimators\n",
    "\n",
    "def run_forest(n_estimators ,X_train, X_test, y_train = y_train, y_test = y_test , random_state = 333):\n",
    "    \n",
    "    acc=[] # list of accuracy which depends on the hyperparameter n_estimators\n",
    "\n",
    "    for num_features in n_estimators: # hyperparameters to change with higher number\n",
    "        forest = RandomForestClassifier(n_estimators=num_features, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt',\n",
    "                                random_state = random_state)\n",
    "        fitted_model=forest.fit(X_train,y_train)\n",
    "        prediction=fitted_model.predict(X_test)\n",
    "        accuracy=accuracy_score(y_test,prediction)\n",
    "        solution = (num_features,accuracy)\n",
    "        acc.append(solution)\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the model, here we can define the lists to put as **n_estimators** argument. My machine cannot handle all these data, for the sake of the example, I just put 1 node for each type of features engineering. You can try with [50,100,200]  and you will see that the accuracy is going to increase, although it cannot go over 20%. Not too much eh? For this we have DL ;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up different number of nodes \n",
    "n_estimators_mean = [1]\n",
    "n_estimators_summaries = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.05715792248879515)]\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the mean\n",
    "accuracy_mean = run_forest(n_estimators_mean,X_train_mean,X_test_mean)\n",
    "print(accuracy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.07835486422356973)]\n"
     ]
    }
   ],
   "source": [
    "# accuracy for the summaries\n",
    "accuracy_summaries = run_forest(n_estimators_summaries,X_train_summaries,X_test_summaries)\n",
    "print(accuracy_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now the moment that all of us were waiting, let's apply Convolutional Neural Network. In this case, we will apply the 2D layer, which is mainly used for image classification, but also in this case we can reach an important accuracy (more than 90%) by reshaping the dimensions of our input shape. For creating this model, I was inspired by this very well done [tutorial](https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python) on DataCamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's upload the data in new variables so that we have everything nice and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name of variables \n",
    "train_X = training_data\n",
    "#test_X = test_data\n",
    "train_Y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said before, we need to reshape the input space, [reshape function](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94824, 99, 13, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape in four dimensions for input CNN\n",
    "train_X = train_X.reshape(-1, 99,13, 1)\n",
    "#test_X = test_X.reshape(-1, 99,13, 1)\n",
    "train_X.shape #, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data type in float\n",
    "train_X = train_X.astype('float32')\n",
    "#test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With CNN we are going to predict a probability for each possible class for each example and for this we need to change again our target. We will use the [to_categorical](https://keras.io/utils/) function. This function creates for each target a list with as many position as number of classes-1 (because it starts from 0) and each *ith* position represents the *ith* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the labels\n",
    "train_Y_one_hot = to_categorical(train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here we can see that the first target is the 22° class, this is because in the 21th position we have 1, while in the others we have 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_one_hot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the model we need of course to create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE THE VALIDATION SET \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, \n",
    "                                                           random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75859, 99, 13, 1), (18965, 99, 13, 1), (75859, 35), (18965, 35))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all the shape\n",
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might know, before running CNN we need to set up some hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparameters \n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "num_classes = 35 # fix\n",
    "np.random.seed(222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our model: 3 CNN2D layers and a fully connected layer before the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the layers \n",
    "fashion_model = Sequential()\n",
    "\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(99,13,1),padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))  \n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 99, 13, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 99, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 50, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 7, 64)         18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 50, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 25, 4, 128)        73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 25, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               426112    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 35)                4515      \n",
      "=================================================================\n",
      "Total params: 523,299\n",
      "Trainable params: 523,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## check the summary\n",
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run. Also here, I just use one epoch for the sake of the example. You should try with at least 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75859 samples, validate on 18965 samples\n",
      "Epoch 1/1\n",
      "75859/75859 [==============================] - 263s 3ms/step - loss: 1.0299 - acc: 0.7024 - val_loss: 0.6447 - val_acc: 0.8129\n"
     ]
    }
   ],
   "source": [
    "## train and test the accuracy in the validation set\n",
    "fashion_train = fashion_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,\n",
    "                                  verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, with this model you should reach 85% accuracy in validation. Not bad eh? However, we can go much more further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to control overfitting by introducing the Dropout function and we hope to improve accuracy. Spoiler alert: we do!\n",
    "\n",
    "To put it simply, during training, some number of layer outputs are randomly ignored or \"dropped out.\" For this we use less parameters and as a result we can control overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparameters \n",
    "batch_size = 124\n",
    "epochs = 1\n",
    "num_classes = 35 # fix\n",
    "np.random.seed(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the dropout to improve accuracy\n",
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(99,13,1),padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.25))\n",
    "\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "fashion_model.add(Dropout(0.4))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation='linear'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))  \n",
    "fashion_model.add(Dropout(0.3))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 99, 13, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 99, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 50, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 50, 7, 64)         18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 50, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 25, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 25, 4, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 4, 128)        73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 25, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 13, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               426112    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 35)                4515      \n",
      "=================================================================\n",
      "Total params: 523,299\n",
      "Trainable params: 523,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75859 samples, validate on 18965 samples\n",
      "Epoch 1/1\n",
      "75859/75859 [==============================] - 343s 5ms/step - loss: 2.4086 - acc: 0.3346 - val_loss: 1.2260 - val_acc: 0.6632\n"
     ]
    }
   ],
   "source": [
    "fashion_train = fashion_model.fit(train_X, train_label, \n",
    "                                  batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                                  validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, with this model you should reach at least 90% accuracy by increasing the number of epochs, let's say a number between 20 and 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althoug, we can reach a good accuracy with 2D layers, the 1D layer turned out to have better accuracy for this data. This is not surprusing, 1D CNN it is widely used for speech recognition. So, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data, reshape and transform the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94824, 99, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#go back to two three dimensions\n",
    "train_X = training_data\n",
    "#test_X = test_data\n",
    "train_Y = labels\n",
    "\n",
    "train_X = train_X.reshape(-1, 99,13)\n",
    "#test_X = test_X.reshape(-1, 99,13)\n",
    "\n",
    "# transform the labels\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "\n",
    "train_X.shape #, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE THE VALIDATION SET \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, \n",
    "                                                           random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up hyperparameters \n",
    "batch_size = 256\n",
    "epochs = 1\n",
    "num_classes = 35 # fix\n",
    "np.random.seed(222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is a very deep model. My group and I spent a lot of time tuning this model because we knew we could reach a very high accuracy. Eventually we were able to reach 95% but I know that it is also possible to get 98%. I leave this challenge to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "\n",
    "fashion_model.add(Conv1D(64, kernel_size=6,activation='relu',padding='same',input_shape=(99,13)))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "\n",
    "fashion_model.add(Dropout(0.2))\n",
    "fashion_model.add(Conv1D(128, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "fashion_model.add(Conv1D(128, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(128, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "fashion_model.add(Conv1D(128, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))\n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(256, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(256, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(256, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(512, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(1024, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Conv1D(1024, kernel_size=6, activation='relu',padding='same'))\n",
    "fashion_model.add(BatchNormalization())\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))                  \n",
    "fashion_model.add(MaxPooling1D(pool_size=2,padding='same'))\n",
    "fashion_model.add(Dropout(0.2))\n",
    "\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(1024, activation='relu'))\n",
    "fashion_model.add(LeakyReLU(alpha=0.1))           \n",
    "fashion_model.add(Dropout(0.2))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 99, 64)            5056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 99, 64)            256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 99, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 50, 128)           98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 25, 128)           98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 13, 128)           98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4, 256)            393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 256)            1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2, 256)            393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 256)            1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 512)            786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1, 1024)           3146752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 1, 1024)           6292480   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 35)                35875     \n",
      "=================================================================\n",
      "Total params: 12,660,707\n",
      "Trainable params: 12,652,899\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fashion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75859 samples, validate on 18965 samples\n",
      "Epoch 1/1\n",
      "75859/75859 [==============================] - 1574s 21ms/step - loss: 2.5870 - acc: 0.2630 - val_loss: 1.7327 - val_acc: 0.5078\n"
     ]
    }
   ],
   "source": [
    "fashion_train = fashion_model.fit(train_X, train_label, \n",
    "                                  batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                                  validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I remember correctly, we trained our model for 100 epochs. As always here, for the sake of the example I just ran it for 1 epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have discussed three different ways of dealing with a speech classification task. First, we tried to solve the problem with a ML algorithm, however, we could not go over 20% accuracy, which is normal becuase this kinds of tasks require to apply DL methods. Therefore, two different types of CNN layers were applied: 2D and 1D. As a result a very high accuracy was reached, although even an higher one is possible to achive.\n",
    "\n",
    "What do we bring home?\n",
    "- These kinds of tasks cannot be solve with classic ML algortihms\n",
    "- A lot of time is recquired for tuning DL models and unfortunately we do not know which one is the best. Try and error is often the standard even if academic and industrial studies can give us some guidelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
